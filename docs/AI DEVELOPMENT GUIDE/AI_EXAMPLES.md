# AI ä¸“å®¶ç³»ç»Ÿ - ç¤ºä¾‹ä»£ç é›†åˆ

æœ¬æ–‡æ¡£æä¾›å®Œæ•´çš„å¯è¿è¡Œç¤ºä¾‹ä»£ç ï¼Œå¸®åŠ©ä½ å¿«é€Ÿç†è§£å’Œä½¿ç”¨ AI ä¸“å®¶ç³»ç»Ÿã€‚

---

## ç›®å½•

- [åŸºç¡€ç¤ºä¾‹](#åŸºç¡€ç¤ºä¾‹)
- [å·¥å…·å‡½æ•°ç¤ºä¾‹](#å·¥å…·å‡½æ•°ç¤ºä¾‹)
- [é«˜çº§åŠŸèƒ½ç¤ºä¾‹](#é«˜çº§åŠŸèƒ½ç¤ºä¾‹)
- [å®é™…åº”ç”¨æ¡ˆä¾‹](#å®é™…åº”ç”¨æ¡ˆä¾‹)

---

## åŸºç¡€ç¤ºä¾‹

### ç¤ºä¾‹ 1: æœ€ç®€å•çš„ AI æŸ¥è¯¢

```python
"""
æœ€ç®€å•çš„ AI ä¸“å®¶ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
"""
import os
from dotenv import load_dotenv
import openai

from waveform_viewer.ai.expert import WaveformExpert
from waveform_viewer.ai.tool_registry import get_default_registry

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# åˆå§‹åŒ–
registry = get_default_registry()
expert = WaveformExpert(openai, registry, model="gpt-4")

# åˆ†æ
result = expert.analyze(
    query="è¿™ä¸ªæ³¢å½¢æœ‰ç”µå‹è·Œè½å—ï¼Ÿ",
    cfg_path="waves/20241030_115240/20241030_115240.cfg"
)

print(result)
```

### ç¤ºä¾‹ 2: äº¤äº’å¼å¯¹è¯

```python
"""
äº¤äº’å¼ AI å¯¹è¯ç¤ºä¾‹
æ”¯æŒå¤šè½®å¯¹è¯ï¼Œä¿æŒä¸Šä¸‹æ–‡
"""
import os
from dotenv import load_dotenv
import openai

from waveform_viewer.ai.expert import WaveformExpert
from waveform_viewer.ai.tool_registry import get_default_registry

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

registry = get_default_registry()
expert = WaveformExpert(openai, registry)

cfg_path = "waves/20241030_115240/20241030_115240.cfg"

print("=== AI ä¸“å®¶å¯¹è¯æ¨¡å¼ ===")
print("è¾“å…¥ 'exit' é€€å‡ºï¼Œè¾“å…¥ 'reset' é‡ç½®å¯¹è¯\n")

while True:
    query = input("æ‚¨çš„é—®é¢˜ > ")

    if query.lower() == 'exit':
        break

    if query.lower() == 'reset':
        expert.reset_conversation()
        print("å¯¹è¯å·²é‡ç½®\n")
        continue

    print("\nğŸ¤– æ­£åœ¨åˆ†æ...\n")
    result = expert.analyze(query, cfg_path)
    print(f"ğŸ“Š åˆ†æç»“æœï¼š\n{result}\n")
    print("-" * 60 + "\n")
```

### ç¤ºä¾‹ 3: æ‰¹é‡åˆ†æ

```python
"""
æ‰¹é‡åˆ†æå¤šä¸ªé—®é¢˜
"""
from waveform_viewer.ai.expert import WaveformExpert
from waveform_viewer.ai.tool_registry import get_default_registry
import openai
import os
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

registry = get_default_registry()
expert = WaveformExpert(openai, registry)

# å®šä¹‰è¦åˆ†æçš„ä»»åŠ¡
tasks = [
    {
        "query": "è¿™ä¸ªæ³¢å½¢æœ‰ç”µå‹è·Œè½å—ï¼Ÿ",
        "cfg_path": "waves/case1.cfg"
    },
    {
        "query": "Aç›¸ç”µæµçš„ç»Ÿè®¡ç‰¹å¾æ˜¯ä»€ä¹ˆï¼Ÿ",
        "cfg_path": "waves/case1.cfg"
    },
    {
        "query": "ä¿æŠ¤è£…ç½®åŠ¨ä½œæ˜¯å¦æ­£ç¡®ï¼Ÿ",
        "cfg_path": "waves/case1.cfg"
    }
]

# æ‰¹é‡åˆ†æ
results = expert.batch_analyze(tasks)

# è¾“å‡ºç»“æœ
for i, (task, result) in enumerate(zip(tasks, results), 1):
    print(f"\n=== é—®é¢˜ {i}: {task['query']} ===")
    print(result)
    print("-" * 60)
```

---

## å·¥å…·å‡½æ•°ç¤ºä¾‹

### ç¤ºä¾‹ 4: åˆ›å»ºè‡ªå®šä¹‰å·¥å…·å‡½æ•°

```python
"""
åˆ›å»ºè‡ªå®šä¹‰çš„åˆ†æå·¥å…·
"""
from waveform_viewer.core.reader import ComtradeReader
import numpy as np
from typing import Dict, Any

def analyze_frequency_stability(cfg_path: str) -> Dict[str, Any]:
    """
    åˆ†æé¢‘ç‡ç¨³å®šæ€§
    """
    try:
        reader = ComtradeReader(cfg_path)

        # æŸ¥æ‰¾é¢‘ç‡é€šé“
        freq_channel = reader.get_channel_by_name("é¢‘ç‡")
        if not freq_channel:
            return {
                "status": "error",
                "message": "æœªæ‰¾åˆ°é¢‘ç‡é€šé“"
            }

        data = np.array(reader.get_analog_data(freq_channel.index))

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        mean_freq = np.mean(data)
        std_freq = np.std(data)
        max_deviation = max(abs(mean_freq - 50), abs(np.min(data) - 50), abs(np.max(data) - 50))

        # åˆ¤æ–­ç¨³å®šæ€§
        if max_deviation < 0.1:
            stability = "ä¼˜ç§€"
        elif max_deviation < 0.3:
            stability = "è‰¯å¥½"
        elif max_deviation < 0.5:
            stability = "ä¸€èˆ¬"
        else:
            stability = "è¾ƒå·®"

        return {
            "status": "success",
            "mean_frequency": float(mean_freq),
            "std_deviation": float(std_freq),
            "min_frequency": float(np.min(data)),
            "max_frequency": float(np.max(data)),
            "max_deviation_from_nominal": float(max_deviation),
            "stability_assessment": stability
        }

    except Exception as e:
        return {
            "status": "error",
            "message": str(e)
        }


# å®šä¹‰å¯¹åº”çš„ Schema
FREQUENCY_STABILITY_SCHEMA = {
    "name": "analyze_frequency_stability",
    "description": "åˆ†æç³»ç»Ÿé¢‘ç‡ç¨³å®šæ€§ã€‚ç”¨äºè¯„ä¼°é¢‘ç‡åå·®ã€æ³¢åŠ¨æƒ…å†µ",
    "parameters": {
        "type": "object",
        "properties": {
            "cfg_path": {
                "type": "string",
                "description": "COMTRADE é…ç½®æ–‡ä»¶è·¯å¾„"
            }
        },
        "required": ["cfg_path"]
    }
}

# æ³¨å†Œåˆ°å·¥å…·æ³¨å†Œè¡¨
from waveform_viewer.ai.tool_registry import get_default_registry

registry = get_default_registry()
registry.register(analyze_frequency_stability, FREQUENCY_STABILITY_SCHEMA)

# ç°åœ¨ AI å°±å¯ä»¥è°ƒç”¨è¿™ä¸ªå·¥å…·äº†ï¼
```

### ç¤ºä¾‹ 5: ä½¿ç”¨è£…é¥°å™¨æ³¨å†Œå·¥å…·

```python
"""
ä½¿ç”¨è£…é¥°å™¨ç®€åŒ–å·¥å…·æ³¨å†Œ
"""
from waveform_viewer.ai.tool_registry import ToolRegistry
from waveform_viewer.core.reader import ComtradeReader
import numpy as np

# åˆ›å»ºæ³¨å†Œè¡¨å®ä¾‹
registry = ToolRegistry()

# ä½¿ç”¨è£…é¥°å™¨æ³¨å†Œ
@registry.register_tool(
    category="power_quality",
    schema={
        "name": "calculate_voltage_unbalance",
        "description": "è®¡ç®—ä¸‰ç›¸ç”µå‹ä¸å¹³è¡¡åº¦",
        "parameters": {
            "type": "object",
            "properties": {
                "cfg_path": {"type": "string", "description": "æ–‡ä»¶è·¯å¾„"}
            },
            "required": ["cfg_path"]
        }
    }
)
def calculate_voltage_unbalance(cfg_path: str):
    """è®¡ç®—ä¸‰ç›¸ç”µå‹ä¸å¹³è¡¡åº¦"""
    reader = ComtradeReader(cfg_path)

    # è·å–ä¸‰ç›¸ç”µå‹
    va = reader.get_channel_by_name("Aç›¸ç”µå‹")
    vb = reader.get_channel_by_name("Bç›¸ç”µå‹")
    vc = reader.get_channel_by_name("Cç›¸ç”µå‹")

    if not (va and vb and vc):
        return {"status": "error", "message": "æœªæ‰¾åˆ°ä¸‰ç›¸ç”µå‹é€šé“"}

    # è®¡ç®— RMS å€¼
    va_rms = np.sqrt(np.mean(np.array(reader.get_analog_data(va.index))**2))
    vb_rms = np.sqrt(np.mean(np.array(reader.get_analog_data(vb.index))**2))
    vc_rms = np.sqrt(np.mean(np.array(reader.get_analog_data(vc.index))**2))

    # è®¡ç®—ä¸å¹³è¡¡åº¦
    v_avg = (va_rms + vb_rms + vc_rms) / 3
    max_deviation = max(abs(va_rms - v_avg), abs(vb_rms - v_avg), abs(vc_rms - v_avg))
    unbalance = (max_deviation / v_avg) * 100

    return {
        "status": "success",
        "voltage_a_rms": float(va_rms),
        "voltage_b_rms": float(vb_rms),
        "voltage_c_rms": float(vc_rms),
        "unbalance_percent": float(unbalance),
        "assessment": "æ­£å¸¸" if unbalance < 2 else "è¶…æ ‡"
    }
```

### ç¤ºä¾‹ 6: ç»„åˆå¤šä¸ªå·¥å…·

```python
"""
åˆ›å»ºé«˜çº§åˆ†æå·¥å…·ï¼Œå†…éƒ¨è°ƒç”¨å¤šä¸ªåŸºç¡€å·¥å…·
"""
from waveform_viewer.ai.tool_registry import get_default_registry

def comprehensive_fault_analysis(cfg_path: str) -> Dict[str, Any]:
    """
    ç»¼åˆæ•…éšœåˆ†æ
    è‡ªåŠ¨è°ƒç”¨å¤šä¸ªå·¥å…·ï¼Œç»™å‡ºå®Œæ•´çš„æ•…éšœè¯Šæ–­æŠ¥å‘Š
    """
    registry = get_default_registry()

    results = {}

    # 1. æ£€æµ‹ç”µå‹è·Œè½
    results['voltage_sags'] = registry.execute('detect_voltage_sags', cfg_path=cfg_path)

    # 2. æ£€æµ‹ç”µæµçªå˜
    results['current_surges'] = registry.execute('detect_current_surges', cfg_path=cfg_path)

    # 3. æå–æ•…éšœæ—¶é—´çº¿
    results['fault_timeline'] = registry.execute('extract_fault_timeline', cfg_path=cfg_path)

    # 4. è¯†åˆ«æ•…éšœç±»å‹
    results['fault_type'] = registry.execute('identify_fault_type', cfg_path=cfg_path)

    # 5. åˆ†æä¿æŠ¤åŠ¨ä½œ
    results['protection'] = registry.execute('analyze_protection_action', cfg_path=cfg_path)

    # ç»¼åˆè¯„ä¼°
    assessment = []

    if results['fault_type']['status'] == 'success':
        assessment.append(f"æ•…éšœç±»å‹: {results['fault_type']['fault_type']}")

    if results['voltage_sags']['event_count'] > 0:
        assessment.append(f"æ£€æµ‹åˆ° {results['voltage_sags']['event_count']} ä¸ªç”µå‹è·Œè½äº‹ä»¶")

    if results['protection']['status'] == 'success':
        assessment.append(f"ä¿æŠ¤åŠ¨ä½œ: {results['protection']['overall_assessment']}")

    return {
        "status": "success",
        "detailed_results": results,
        "summary": assessment
    }
```

---

## é«˜çº§åŠŸèƒ½ç¤ºä¾‹

### ç¤ºä¾‹ 7: æµå¼è¾“å‡º

```python
"""
æµå¼è¾“å‡º AI å›ç­”ï¼Œæ”¹å–„ç”¨æˆ·ä½“éªŒ
"""
from waveform_viewer.ai.expert import WaveformExpert

class StreamingExpert(WaveformExpert):
    """æ”¯æŒæµå¼è¾“å‡ºçš„ä¸“å®¶ç³»ç»Ÿ"""

    def analyze_stream(self, query: str, cfg_path: str):
        """æµå¼è¿”å›åˆ†æç»“æœ"""
        system_prompt = self._build_system_prompt(cfg_path)

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query}
        ]

        # ä½¿ç”¨æµå¼ API
        response = self.openai.chat.completions.create(
            model=self.model,
            messages=messages,
            functions=self.registry.get_all_schemas(),
            stream=True,
            temperature=0.1
        )

        buffer = ""
        for chunk in response:
            delta = chunk.choices[0].delta

            # å¤„ç†æ–‡æœ¬å†…å®¹
            if delta.content:
                buffer += delta.content
                yield delta.content

            # å¤„ç†å‡½æ•°è°ƒç”¨ï¼ˆéæµå¼ï¼‰
            if delta.function_call:
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                func_name = delta.function_call.name
                func_args = json.loads(delta.function_call.arguments)

                result = self.registry.execute(func_name, **func_args)

                # ç»§ç»­æµå¼è¾“å‡ºç»“æœè§£é‡Š
                # ï¼ˆéœ€è¦å†æ¬¡è°ƒç”¨ LLMï¼‰
                yield f"\n\n[è°ƒç”¨å·¥å…·: {func_name}]\n"

        return buffer


# ä½¿ç”¨ç¤ºä¾‹
import sys

expert = StreamingExpert(openai, registry)

print("ğŸ¤– AI åˆ†æä¸­", end="", flush=True)

for chunk in expert.analyze_stream("åˆ†æè¿™ä¸ªæ•…éšœ", "waves/test.cfg"):
    print(chunk, end="", flush=True)

print("\n\nâœ… åˆ†æå®Œæˆ")
```

### ç¤ºä¾‹ 8: ä¸Šä¸‹æ–‡ç®¡ç†å’Œå‹ç¼©

```python
"""
æ™ºèƒ½ç®¡ç†å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œé¿å…è¶…å‡º Token é™åˆ¶
"""
from typing import List, Dict
import tiktoken

class ContextManager:
    """å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self, max_tokens: int = 8000):
        self.max_tokens = max_tokens
        self.history: List[Dict] = []
        self.tokenizer = tiktoken.encoding_for_model("gpt-4")

    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        self.history.append({"role": role, "content": content})

    def count_tokens(self, messages: List[Dict]) -> int:
        """è®¡ç®—æ¶ˆæ¯çš„ token æ•°"""
        text = "\n".join([m.get("content", "") for m in messages])
        return len(self.tokenizer.encode(text))

    def get_context(self, system_prompt: str) -> List[Dict]:
        """è·å–é€‚åˆçš„ä¸Šä¸‹æ–‡ï¼ˆè‡ªåŠ¨å‹ç¼©ï¼‰"""
        messages = [{"role": "system", "content": system_prompt}]

        # è®¡ç®—ç³»ç»Ÿæç¤ºè¯çš„ token
        system_tokens = self.count_tokens(messages)

        # ä»æœ€æ–°å¼€å§‹æ·»åŠ å†å²æ¶ˆæ¯
        remaining_tokens = self.max_tokens - system_tokens
        recent_history = []

        for msg in reversed(self.history):
            msg_tokens = self.count_tokens([msg])
            if remaining_tokens - msg_tokens > 0:
                recent_history.insert(0, msg)
                remaining_tokens -= msg_tokens
            else:
                break

        messages.extend(recent_history)
        return messages

    def compress_history(self, llm_client):
        """å‹ç¼©æ—©æœŸå¯¹è¯å†å²"""
        if len(self.history) <= 6:  # å°‘äº3è½®å¯¹è¯ï¼Œä¸å‹ç¼©
            return

        # å‹ç¼©é™¤æœ€è¿‘3è½®å¤–çš„æ‰€æœ‰å¯¹è¯
        old_messages = self.history[:-6]
        recent_messages = self.history[-6:]

        # ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
        summary_prompt = f"""è¯·ç®€è¦æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„å…³é”®ä¿¡æ¯ï¼š
{old_messages}

è¦æ±‚ï¼š
1. ä¿ç•™é‡è¦çš„åˆ†æç»“æœ
2. ä¿ç•™ç”¨æˆ·å…³æ³¨çš„é‡ç‚¹
3. æ§åˆ¶åœ¨100å­—ä»¥å†…"""

        response = llm_client.chat.completions.create(
            model="gpt-3.5-turbo",  # ç”¨ä¾¿å®œçš„æ¨¡å‹åšæ‘˜è¦
            messages=[{"role": "user", "content": summary_prompt}],
            max_tokens=200
        )

        summary = response.choices[0].message.content

        # æ›¿æ¢å†å²
        self.history = [
            {"role": "system", "content": f"[æ—©æœŸå¯¹è¯æ‘˜è¦]: {summary}"},
            *recent_messages
        ]


# é›†æˆåˆ° Expert
class ContextAwareExpert(WaveformExpert):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.context_manager = ContextManager(max_tokens=8000)

    def analyze(self, query: str, cfg_path: str):
        system_prompt = self._build_system_prompt(cfg_path)

        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è·å–æ¶ˆæ¯
        messages = self.context_manager.get_context(system_prompt)
        messages.append({"role": "user", "content": query})

        # ... è°ƒç”¨ LLM

        # æ·»åŠ åˆ°å†å²
        self.context_manager.add_message("user", query)
        self.context_manager.add_message("assistant", answer)

        # å¦‚æœæ¥è¿‘é™åˆ¶ï¼Œå‹ç¼©å†å²
        if self.context_manager.count_tokens(self.context_manager.history) > 6000:
            self.context_manager.compress_history(self.openai)

        return answer
```

### ç¤ºä¾‹ 9: å¤šæ¨¡å‹æ”¯æŒ

```python
"""
æ”¯æŒå¤šä¸ª LLM æä¾›å•†
"""
from abc import ABC, abstractmethod

class LLMClient(ABC):
    """LLM å®¢æˆ·ç«¯æŠ½è±¡åŸºç±»"""

    @abstractmethod
    def chat(self, messages, tools, **kwargs):
        pass


class OpenAIClient(LLMClient):
    """OpenAI å®¢æˆ·ç«¯"""

    def __init__(self, api_key: str, model: str = "gpt-4"):
        import openai
        self.openai = openai
        self.openai.api_key = api_key
        self.model = model

    def chat(self, messages, tools, **kwargs):
        response = self.openai.chat.completions.create(
            model=self.model,
            messages=messages,
            functions=tools,
            **kwargs
        )
        return self._normalize_response(response)

    def _normalize_response(self, response):
        """æ ‡å‡†åŒ–å“åº”æ ¼å¼"""
        message = response.choices[0].message

        result = {
            "content": message.content,
            "tool_calls": []
        }

        if message.function_call:
            result["tool_calls"].append({
                "name": message.function_call.name,
                "arguments": json.loads(message.function_call.arguments)
            })

        return result


class ClaudeClient(LLMClient):
    """Claude å®¢æˆ·ç«¯"""

    def __init__(self, api_key: str, model: str = "claude-3-5-sonnet-20241022"):
        import anthropic
        self.anthropic = anthropic.Anthropic(api_key=api_key)
        self.model = model

    def chat(self, messages, tools, **kwargs):
        # è½¬æ¢å·¥å…·æ ¼å¼
        claude_tools = self._convert_tools(tools)

        response = self.anthropic.messages.create(
            model=self.model,
            max_tokens=4096,
            messages=messages[1:],  # è·³è¿‡ system æ¶ˆæ¯
            system=messages[0]["content"],
            tools=claude_tools,
            **kwargs
        )

        return self._normalize_response(response)

    def _convert_tools(self, openai_tools):
        """è½¬æ¢ OpenAI æ ¼å¼åˆ° Claude æ ¼å¼"""
        return [
            {
                "name": tool["name"],
                "description": tool["description"],
                "input_schema": tool["parameters"]
            }
            for tool in openai_tools
        ]

    def _normalize_response(self, response):
        result = {
            "content": "",
            "tool_calls": []
        }

        for block in response.content:
            if block.type == "text":
                result["content"] += block.text
            elif block.type == "tool_use":
                result["tool_calls"].append({
                    "name": block.name,
                    "arguments": block.input
                })

        return result


# å·¥å‚æ¨¡å¼
class LLMFactory:
    @staticmethod
    def create(provider: str, **kwargs) -> LLMClient:
        if provider == "openai":
            return OpenAIClient(**kwargs)
        elif provider == "anthropic":
            return ClaudeClient(**kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")


# ä½¿ç”¨
import os
from dotenv import load_dotenv

load_dotenv()

# åˆ›å»ºå®¢æˆ·ç«¯
llm = LLMFactory.create(
    provider="openai",  # æˆ– "anthropic"
    api_key=os.getenv("OPENAI_API_KEY"),
    model="gpt-4"
)

# åˆ›å»ºä¸“å®¶ç³»ç»Ÿ
from waveform_viewer.ai.expert import WaveformExpert
from waveform_viewer.ai.tool_registry import get_default_registry

registry = get_default_registry()
expert = WaveformExpert(llm, registry)

# ä½¿ç”¨æ–¹å¼å®Œå…¨ç›¸åŒ
result = expert.analyze("åˆ†ææ•…éšœ", "waves/test.cfg")
```

---

## å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ 1: è‡ªåŠ¨æ•…éšœè¯Šæ–­è„šæœ¬

```python
"""
è‡ªåŠ¨æ•…éšœè¯Šæ–­è„šæœ¬
è¯»å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰å½•æ³¢æ–‡ä»¶ï¼Œè‡ªåŠ¨ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
"""
import os
from pathlib import Path
from waveform_viewer.ai.expert import WaveformExpert
from waveform_viewer.ai.tool_registry import get_default_registry
import openai
from dotenv import load_dotenv
import json
from datetime import datetime

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

registry = get_default_registry()
expert = WaveformExpert(openai, registry)


def auto_diagnose_directory(waves_dir: str, output_dir: str):
    """è‡ªåŠ¨è¯Šæ–­ç›®å½•ä¸‹æ‰€æœ‰æ³¢å½¢æ–‡ä»¶"""

    waves_path = Path(waves_dir)
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)

    # æŸ¥æ‰¾æ‰€æœ‰ .cfg æ–‡ä»¶
    cfg_files = list(waves_path.rglob("*.cfg"))

    print(f"æ‰¾åˆ° {len(cfg_files)} ä¸ªå½•æ³¢æ–‡ä»¶")

    results = []

    for i, cfg_file in enumerate(cfg_files, 1):
        print(f"\n[{i}/{len(cfg_files)}] åˆ†æ: {cfg_file.name}")

        # é‡ç½®å¯¹è¯ï¼ˆæ¯ä¸ªæ–‡ä»¶ç‹¬ç«‹åˆ†æï¼‰
        expert.reset_conversation()

        try:
            # æ‰§è¡Œè¯Šæ–­æŸ¥è¯¢
            diagnosis = expert.analyze(
                query="""è¯·å¯¹è¿™ä¸ªå½•æ³¢æ–‡ä»¶è¿›è¡Œå…¨é¢è¯Šæ–­ï¼ŒåŒ…æ‹¬ï¼š
1. æ˜¯å¦å‘ç”Ÿæ•…éšœï¼Ÿä»€ä¹ˆç±»å‹çš„æ•…éšœï¼Ÿ
2. ç”µå‹å’Œç”µæµæœ‰ä»€ä¹ˆå¼‚å¸¸ï¼Ÿ
3. ä¿æŠ¤è£…ç½®åŠ¨ä½œæ˜¯å¦æ­£ç¡®ï¼Ÿ
4. ç»™å‡ºè¯Šæ–­ç»“è®ºå’Œå»ºè®®""",
                cfg_path=str(cfg_file)
            )

            result = {
                "file": str(cfg_file),
                "timestamp": datetime.now().isoformat(),
                "diagnosis": diagnosis,
                "status": "success"
            }

        except Exception as e:
            result = {
                "file": str(cfg_file),
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
                "status": "error"
            }

        results.append(result)

        # ä¿å­˜å•ä¸ªç»“æœ
        output_file = output_path / f"{cfg_file.stem}_diagnosis.txt"
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(f"æ–‡ä»¶: {cfg_file}\n")
            f.write(f"æ—¶é—´: {result['timestamp']}\n")
            f.write(f"\n{'='*60}\n\n")
            f.write(result.get('diagnosis', result.get('error', '')))

        print(f"  âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
    summary_file = output_path / "summary.json"
    with open(summary_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ‰€æœ‰åˆ†æå®Œæˆï¼æ±‡æ€»æŠ¥å‘Š: {summary_file}")


# ä½¿ç”¨
if __name__ == "__main__":
    auto_diagnose_directory(
        waves_dir="waves/",
        output_dir="diagnosis_reports/"
    )
```

### æ¡ˆä¾‹ 2: æ‰¹é‡ç”µèƒ½è´¨é‡è¯„ä¼°

```python
"""
æ‰¹é‡è¯„ä¼°ç”µèƒ½è´¨é‡
"""
from waveform_viewer.ai.expert import WaveformExpert
from waveform_viewer.ai.tool_registry import get_default_registry
import pandas as pd

def batch_power_quality_assessment(cfg_files: List[str]) -> pd.DataFrame:
    """
    æ‰¹é‡è¯„ä¼°ç”µèƒ½è´¨é‡

    Returns:
        DataFrame åŒ…å«æ‰€æœ‰æ–‡ä»¶çš„ç”µèƒ½è´¨é‡æŒ‡æ ‡
    """
    registry = get_default_registry()

    results = []

    for cfg_file in cfg_files:
        # ä½¿ç”¨å·¥å…·ç›´æ¥è®¡ç®—ï¼ˆä¸éœ€è¦ LLMï¼‰
        pq_metrics = registry.execute('calculate_power_quality_metrics', cfg_path=cfg_file)

        if pq_metrics['status'] == 'success':
            results.append({
                'file': cfg_file,
                'voltage_deviation_A': pq_metrics['voltage_deviation']['A'],
                'voltage_unbalance': pq_metrics['voltage_unbalance'],
                'thd_voltage_A': pq_metrics['thd_voltage']['A'],
                'frequency_deviation': pq_metrics['frequency_deviation'],
                'assessment': pq_metrics['overall_assessment']
            })

    df = pd.DataFrame(results)

    # æ ‡è®°ä¸åˆæ ¼é¡¹
    df['voltage_deviation_ok'] = df['voltage_deviation_A'].abs() < 7  # GB/T 12325
    df['voltage_unbalance_ok'] = df['voltage_unbalance'] < 2
    df['thd_ok'] = df['thd_voltage_A'] < 5
    df['frequency_ok'] = df['frequency_deviation'].abs() < 0.5

    return df


# ä½¿ç”¨
cfg_files = [
    "waves/case1.cfg",
    "waves/case2.cfg",
    "waves/case3.cfg"
]

df = batch_power_quality_assessment(cfg_files)

# è¾“å‡ºåˆ° Excel
df.to_excel("power_quality_report.xlsx", index=False)

# æ‰“å°ä¸åˆæ ¼é¡¹
failed = df[~(df['voltage_deviation_ok'] & df['voltage_unbalance_ok'] &
              df['thd_ok'] & df['frequency_ok'])]

print(f"\nå‘ç° {len(failed)} ä¸ªç”µèƒ½è´¨é‡ä¸åˆæ ¼çš„æ–‡ä»¶ï¼š")
print(failed[['file', 'assessment']])
```

### æ¡ˆä¾‹ 3: å¯¹æ¯”åˆ†æå·¥å…·

```python
"""
å¯¹æ¯”åˆ†æå¤šä¸ªå½•æ³¢æ–‡ä»¶
"""
def compare_multiple_waveforms(cfg_files: List[str], reference_file: str):
    """
    å°†å¤šä¸ªæ–‡ä»¶ä¸å‚è€ƒæ–‡ä»¶å¯¹æ¯”
    """
    from waveform_viewer.ai.tool_registry import get_default_registry

    registry = get_default_registry()

    print(f"å‚è€ƒæ–‡ä»¶: {reference_file}\n")

    for cfg_file in cfg_files:
        print(f"\nå¯¹æ¯”æ–‡ä»¶: {cfg_file}")
        print("=" * 60)

        # å¯¹æ¯” A ç›¸ç”µå‹
        comparison = registry.execute(
            'compare_waveforms',
            cfg_paths=[reference_file, cfg_file],
            channel_name="Aç›¸ç”µå‹"
        )

        if comparison['status'] == 'success':
            sim = comparison['comparison']['similarity']
            corr = comparison['comparison']['correlation']

            print(f"ç›¸ä¼¼åº¦: {sim}")
            print(f"ç›¸å…³ç³»æ•°: {corr:.3f}")

            if corr > 0.95:
                print("âœ… æ³¢å½¢é«˜åº¦ç›¸ä¼¼")
            elif corr > 0.8:
                print("âš ï¸ æ³¢å½¢å­˜åœ¨å·®å¼‚")
            else:
                print("âŒ æ³¢å½¢å·®å¼‚æ˜¾è‘—")

        # åŸºçº¿åå·®åˆ†æ
        deviation = registry.execute(
            'baseline_deviation_analysis',
            cfg_path=cfg_file,
            baseline_cfg_path=reference_file
        )

        if deviation['status'] == 'success':
            for dev in deviation['deviations']:
                if dev['exceeds_threshold']:
                    print(f"\nâš ï¸ {dev['channel']} åå·® {dev['deviation_percent']:.1f}%")


# ä½¿ç”¨
compare_multiple_waveforms(
    cfg_files=[
        "waves/day1.cfg",
        "waves/day2.cfg",
        "waves/day3.cfg"
    ],
    reference_file="waves/baseline.cfg"
)
```

### æ¡ˆä¾‹ 4: ç”Ÿæˆ HTML æŠ¥å‘Š

```python
"""
ç”Ÿæˆç¾è§‚çš„ HTML åˆ†ææŠ¥å‘Š
"""
def generate_html_report(cfg_path: str, output_path: str):
    """ç”ŸæˆåŒ…å«å¯è§†åŒ–çš„ HTML æŠ¥å‘Š"""

    from waveform_viewer.ai.expert import WaveformExpert
    from waveform_viewer.ai.tool_registry import get_default_registry
    import openai
    from dotenv import load_dotenv

    load_dotenv()
    openai.api_key = os.getenv("OPENAI_API_KEY")

    registry = get_default_registry()
    expert = WaveformExpert(openai, registry)

    # æ‰§è¡Œåˆ†æ
    analysis = expert.analyze(
        query="è¯·å¯¹è¿™ä¸ªå½•æ³¢è¿›è¡Œå…¨é¢åˆ†æï¼ŒåŒ…æ‹¬æ•…éšœè¯Šæ–­ã€ä¿æŠ¤è¯„ä»·ã€ç”µèƒ½è´¨é‡è¯„ä¼°",
        cfg_path=cfg_path
    )

    # ç”Ÿæˆå¯è§†åŒ–
    viz_result = registry.execute(
        'create_visualization',
        cfg_path=cfg_path,
        channel_names=["Aç›¸ç”µå‹", "Aç›¸ç”µæµ"],
        output_path="temp_viz.html"
    )

    # è¯»å–å¯è§†åŒ– HTML
    with open("temp_viz.html", "r") as f:
        viz_html = f.read()

    # ç”ŸæˆæŠ¥å‘Š HTML
    html_template = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>å½•æ³¢åˆ†ææŠ¥å‘Š</title>
    <style>
        body {{
            font-family: "Microsoft YaHei", Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 20px;
        }}
        .section {{
            background: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .section h2 {{
            color: #667eea;
            border-bottom: 2px solid #667eea;
            padding-bottom: 10px;
        }}
        pre {{
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ“Š COMTRADE å½•æ³¢åˆ†ææŠ¥å‘Š</h1>
        <p>æ–‡ä»¶: {cfg_path}</p>
        <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    </div>

    <div class="section">
        <h2>ğŸ¤– AI åˆ†æç»“è®º</h2>
        <pre>{analysis}</pre>
    </div>

    <div class="section">
        <h2>ğŸ“ˆ æ³¢å½¢å¯è§†åŒ–</h2>
        {viz_html}
    </div>

    <div class="section">
        <h2>â„¹ï¸ åˆ†æè¯´æ˜</h2>
        <p>æœ¬æŠ¥å‘Šç”± ComtradeReader AI ä¸“å®¶ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆã€‚</p>
        <p>ä½¿ç”¨æ¨¡å‹: GPT-4</p>
    </div>
</body>
</html>
    """

    # ä¿å­˜æŠ¥å‘Š
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(html_template)

    print(f"âœ… HTML æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")


# ä½¿ç”¨
generate_html_report(
    cfg_path="waves/20241030_115240/20241030_115240.cfg",
    output_path="analysis_report.html"
)
```

---

## è°ƒè¯•å’Œæµ‹è¯•ç¤ºä¾‹

### ç¤ºä¾‹ 10: è°ƒè¯•å·¥å…·è°ƒç”¨

```python
"""
è°ƒè¯•æ¨¡å¼ï¼šæŸ¥çœ‹å·¥å…·è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯
"""
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

class DebugExpert(WaveformExpert):
    """å¸¦è°ƒè¯•åŠŸèƒ½çš„ä¸“å®¶ç³»ç»Ÿ"""

    def analyze(self, query: str, cfg_path: str):
        print(f"\n{'='*60}")
        print(f"ğŸ” å¼€å§‹åˆ†æ")
        print(f"é—®é¢˜: {query}")
        print(f"æ–‡ä»¶: {cfg_path}")
        print(f"{'='*60}\n")

        # ... åŸæœ‰é€»è¾‘ ...

        # åœ¨å·¥å…·è°ƒç”¨æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
        print(f"\nğŸ› ï¸  è°ƒç”¨å·¥å…·: {func_name}")
        print(f"ğŸ“¥ å‚æ•°: {json.dumps(func_args, ensure_ascii=False, indent=2)}")

        result = self.registry.execute(func_name, **func_args)

        print(f"ğŸ“¤ ç»“æœ: {json.dumps(result, ensure_ascii=False, indent=2)[:500]}...")

        # ç»§ç»­...


# ä½¿ç”¨
debug_expert = DebugExpert(openai, registry)
debug_expert.analyze("ç”µå‹æœ‰è·Œè½å—ï¼Ÿ", "waves/test.cfg")
```

### ç¤ºä¾‹ 11: å•å…ƒæµ‹è¯•

```python
"""
å·¥å…·å‡½æ•°çš„å•å…ƒæµ‹è¯•
"""
import unittest
from waveform_viewer.ai.tools.basic_analysis import calculate_statistics, detect_voltage_sags

class TestAnalysisTools(unittest.TestCase):
    """æµ‹è¯•åˆ†æå·¥å…·"""

    def setUp(self):
        self.test_cfg = "waves/20241030_115240/20241030_115240.cfg"

    def test_calculate_statistics(self):
        """æµ‹è¯•ç»Ÿè®¡è®¡ç®—"""
        result = calculate_statistics(self.test_cfg, "Aç›¸ç”µå‹")

        self.assertEqual(result['status'], 'success')
        self.assertIn('statistics', result)
        self.assertIn('min', result['statistics'])
        self.assertIn('max', result['statistics'])
        self.assertGreater(result['statistics']['max'], result['statistics']['min'])

    def test_detect_voltage_sags(self):
        """æµ‹è¯•ç”µå‹è·Œè½æ£€æµ‹"""
        result = detect_voltage_sags(self.test_cfg, threshold_percent=90)

        self.assertEqual(result['status'], 'success')
        self.assertIn('events', result)
        self.assertIsInstance(result['events'], list)

    def test_invalid_file(self):
        """æµ‹è¯•æ— æ•ˆæ–‡ä»¶å¤„ç†"""
        result = calculate_statistics("nonexistent.cfg", "Aç›¸ç”µå‹")

        self.assertEqual(result['status'], 'error')
        self.assertIn('message', result)


if __name__ == '__main__':
    unittest.main()
```

---

## æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹

### ç¤ºä¾‹ 12: ç¼“å­˜å·¥å…·ç»“æœ

```python
"""
ç¼“å­˜å·¥å…·æ‰§è¡Œç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
"""
import hashlib
import json
from functools import wraps

class ToolResultCache:
    """å·¥å…·ç»“æœç¼“å­˜"""

    def __init__(self):
        self._cache = {}

    def get_cache_key(self, tool_name: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = f"{tool_name}:{json.dumps(kwargs, sort_keys=True)}"
        return hashlib.md5(key_str.encode()).hexdigest()

    def cached_execute(self, tool_func):
        """ç¼“å­˜è£…é¥°å™¨"""
        @wraps(tool_func)
        def wrapper(**kwargs):
            cache_key = self.get_cache_key(tool_func.__name__, **kwargs)

            # æ£€æŸ¥ç¼“å­˜
            if cache_key in self._cache:
                print(f"  ğŸ’¾ ä½¿ç”¨ç¼“å­˜: {tool_func.__name__}")
                return self._cache[cache_key]

            # æ‰§è¡Œå·¥å…·
            result = tool_func(**kwargs)

            # ä¿å­˜åˆ°ç¼“å­˜
            self._cache[cache_key] = result

            return result

        return wrapper


# ä½¿ç”¨ç¼“å­˜
cache = ToolResultCache()

@cache.cached_execute
def calculate_statistics(cfg_path, channel_name):
    # å®é™…çš„å·¥å…·å‡½æ•°
    ...
```

---

**æ›´å¤šç¤ºä¾‹æŒç»­æ›´æ–°...**

å¦‚æœ‰é—®é¢˜æˆ–éœ€è¦æ›´å¤šç¤ºä¾‹ï¼Œè¯·å‚è€ƒï¼š
- [å®Œæ•´å¼€å‘æŒ‡å—](./AI_INTEGRATION_GUIDE.md)
- [å·¥å…·å‡½æ•°å‚è€ƒ](./AI_TOOLS_REFERENCE.md)
- [æ¶æ„è®¾è®¡æ–‡æ¡£](./AI_ARCHITECTURE.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2024-11-10
